{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Association_Rule_Rerank_submit.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVnGSv6cxVKj"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import math\n",
        "\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
        "\n",
        "\n",
        "import tokenizers\n",
        "from tokenizers import Tokenizer\n",
        "from transformers import BertTokenizerFast, BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErHAaW6pQ46l"
      },
      "source": [
        "import os.path as osp\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import download_url, Data\n",
        "from torch_geometric.data import Dataset as GeoDataset\n",
        "from torch_geometric.data import DataLoader as GeoDataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gpao3ymyTBg"
      },
      "source": [
        "#Need a special generator for random sampling:\n",
        "\n",
        "\n",
        "class GenerateData():\n",
        "  def __init__(self, path_train, path_val, path_test, path_molecules, path_token_embs):\n",
        "    self.path_train = path_train\n",
        "    self.path_val = path_val\n",
        "    self.path_test = path_test\n",
        "    self.path_molecules = path_molecules\n",
        "    self.path_token_embs = path_token_embs\n",
        "\n",
        "    self.mol_trunc_length = 512\n",
        "    self.text_trunc_length = 256 \n",
        "\n",
        "    self.prep_text_tokenizer()\n",
        "    \n",
        "    self.load_substructures()\n",
        "\n",
        "    self.batch_size = 32\n",
        "\n",
        "    self.store_descriptions()\n",
        "    \n",
        "  def load_substructures(self):\n",
        "    self.molecule_sentences = {}\n",
        "    self.molecule_tokens = {}\n",
        "\n",
        "    total_tokens = set()\n",
        "    self.max_mol_length = 0\n",
        "    with open(self.path_molecules) as f:\n",
        "      for line in f:\n",
        "        spl = line.split(\":\")\n",
        "        cid = spl[0]\n",
        "        tokens = spl[1].strip()\n",
        "        self.molecule_sentences[cid] = tokens\n",
        "        t = tokens.split()\n",
        "        total_tokens.update(t)\n",
        "        size = len(t)\n",
        "        if size > self.max_mol_length: self.max_mol_length = size\n",
        "\n",
        "\n",
        "    self.token_embs = np.load(self.path_token_embs, allow_pickle = True)[()]\n",
        "\n",
        "\n",
        "\n",
        "  def prep_text_tokenizer(self):\n",
        "    self.text_tokenizer = BertTokenizerFast.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        " \n",
        "\n",
        "  def store_descriptions(self):\n",
        "    self.descriptions = {}\n",
        "    \n",
        "    self.mols = {}\n",
        "\n",
        "\n",
        "\n",
        "    self.training_cids = []\n",
        "    #get training set cids...\n",
        "    with open(self.path_train) as f:\n",
        "      reader = csv.DictReader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, fieldnames = ['cid', 'mol2vec', 'desc'])\n",
        "      for n, line in enumerate(reader):\n",
        "        self.descriptions[line['cid']] = line['desc']\n",
        "        self.mols[line['cid']] = line['mol2vec']\n",
        "        self.training_cids.append(line['cid'])\n",
        "        \n",
        "    self.validation_cids = []\n",
        "    #get validation set cids...\n",
        "    with open(self.path_val) as f:\n",
        "      reader = csv.DictReader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, fieldnames = ['cid', 'mol2vec', 'desc'])\n",
        "      for n, line in enumerate(reader):\n",
        "        self.descriptions[line['cid']] = line['desc']\n",
        "        self.mols[line['cid']] = line['mol2vec']\n",
        "        self.validation_cids.append(line['cid'])\n",
        "        \n",
        "    self.test_cids = []\n",
        "    with open(self.path_test) as f:\n",
        "      reader = csv.DictReader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE, fieldnames = ['cid', 'mol2vec', 'desc'])\n",
        "      for n, line in enumerate(reader):\n",
        "        self.descriptions[line['cid']] = line['desc']\n",
        "        self.mols[line['cid']] = line['mol2vec']\n",
        "        self.test_cids.append(line['cid'])\n",
        "\n",
        "  #transformers can't take array with full attention so have to pad a 0...\n",
        "  def padarray(self, A, size, value=0):\n",
        "      t = size - len(A)\n",
        "      return np.pad(A, pad_width=(0, t), mode='constant', constant_values = value)\n",
        "\n",
        "\n",
        "  def generate_examples_train(self):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "\n",
        "    np.random.shuffle(self.training_cids)\n",
        "\n",
        "    for cid in self.training_cids:\n",
        "      label = np.random.randint(2)\n",
        "      rand_cid = np.random.choice(self.training_cids)\n",
        "      if label:\n",
        "        text_input = self.text_tokenizer(self.descriptions[cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "      else:\n",
        "        text_input = self.text_tokenizer(self.descriptions[rand_cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "\n",
        "      text_ids = self.padarray(text_input['input_ids'].squeeze(), self.text_trunc_length)\n",
        "      text_mask = self.padarray(text_input['attention_mask'].squeeze(), self.text_trunc_length)\n",
        "\n",
        "      yield {\n",
        "          'cid': cid,\n",
        "          'input': {\n",
        "              'text': {\n",
        "                'input_ids': text_ids,\n",
        "                'attention_mask': text_mask,\n",
        "              },\n",
        "              'molecule' : {\n",
        "                    'mol2vec' : np.fromstring(self.mols[cid], sep = \" \"),\n",
        "                    'cid' : cid\n",
        "              },         \n",
        "          },\n",
        "          'label': label\n",
        "      }\n",
        "\n",
        "\n",
        "  def generate_examples_val(self):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "\n",
        "    np.random.shuffle(self.validation_cids)\n",
        "\n",
        "    for cid in self.validation_cids:\n",
        "      label = np.random.randint(2)\n",
        "      rand_cid = np.random.choice(self.validation_cids)\n",
        "      if label:\n",
        "        text_input = self.text_tokenizer(self.descriptions[cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "      else:\n",
        "        text_input = self.text_tokenizer(self.descriptions[rand_cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "\n",
        "\n",
        "      text_ids = self.padarray(text_input['input_ids'].squeeze(), self.text_trunc_length)\n",
        "      text_mask = self.padarray(text_input['attention_mask'].squeeze(), self.text_trunc_length)\n",
        "\n",
        "      yield {\n",
        "          'cid': cid,\n",
        "          'input': {\n",
        "              'text': {\n",
        "                'input_ids': text_ids,\n",
        "                'attention_mask': text_mask,\n",
        "              },\n",
        "              'molecule' : {\n",
        "                    'mol2vec' : np.fromstring(self.mols[cid], sep = \" \"),\n",
        "                    'cid' : cid\n",
        "              },         \n",
        "          },\n",
        "          'label': label\n",
        "      }\n",
        "\n",
        "  def generate_examples_test(self):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "\n",
        "    np.random.shuffle(self.test_cids)\n",
        "\n",
        "    for cid in self.test_cids:\n",
        "      label = np.random.randint(2)\n",
        "      rand_cid = np.random.choice(self.test_cids)\n",
        "      if label:\n",
        "        text_input = self.text_tokenizer(self.descriptions[cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "      else:\n",
        "        text_input = self.text_tokenizer(self.descriptions[rand_cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "\n",
        "\n",
        "      text_ids = self.padarray(text_input['input_ids'].squeeze(), self.text_trunc_length)\n",
        "      text_mask = self.padarray(text_input['attention_mask'].squeeze(), self.text_trunc_length)\n",
        "\n",
        "      yield {\n",
        "          'cid': cid,\n",
        "          'input': {\n",
        "              'text': {\n",
        "                'input_ids': text_ids,\n",
        "                'attention_mask': text_mask,\n",
        "              },\n",
        "              'molecule' : {\n",
        "                    'mol2vec' : np.fromstring(self.mols[cid], sep = \" \"),\n",
        "                    'cid' : cid\n",
        "              },         \n",
        "          },\n",
        "          'label': label\n",
        "      }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mounted_path_token_embs = \"input/token_embedding_dict.npy\"\n",
        "mounted_path_train = \"input/mol2vec_ChEBI_20_training.txt\"\n",
        "mounted_path_val = \"input/mol2vec_ChEBI_20_val.txt\"\n",
        "mounted_path_test = \"input/mol2vec_ChEBI_20_test.txt\"\n",
        "mounted_path_molecules = \"input/ChEBI_defintions_substructure_corpus.cp\"\n",
        "gt = GenerateData(mounted_path_train, mounted_path_val, mounted_path_test, mounted_path_molecules, mounted_path_token_embs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zck-zGTa8JOv"
      },
      "source": [
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, gen, length):\n",
        "      'Initialization'\n",
        "\n",
        "      self.gen = gen\n",
        "      self.it = iter(self.gen())\n",
        "\n",
        "      self.length = length\n",
        "\n",
        "  def __len__(self):\n",
        "      'Denotes the total number of samples'\n",
        "      return self.length\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      'Generates one sample of data'\n",
        "\n",
        "      try:\n",
        "        ex = next(self.it)\n",
        "      except StopIteration:\n",
        "        self.it = iter(self.gen())\n",
        "        ex = next(self.it)\n",
        "\n",
        "      X = ex['input']\n",
        "      y = ex['label']\n",
        "\n",
        "      return X, y\n",
        "\n",
        "training_set = Dataset(gt.generate_examples_train, len(gt.training_cids))\n",
        "validation_set = Dataset(gt.generate_examples_val, len(gt.validation_cids))\n",
        "test_set = Dataset(gt.generate_examples_test, len(gt.test_cids))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fj8h8vhk3W0"
      },
      "source": [
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 1,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 1}\n",
        "\n",
        "training_generator = DataLoader(training_set, **params)\n",
        "validation_generator = DataLoader(validation_set, **params)\n",
        "test_generator = DataLoader(test_set, **params)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvbObrE0QwQT"
      },
      "source": [
        "\n",
        "class MoleculeGraphDataset(GeoDataset):\n",
        "    def __init__(self, root, cids, data_path, gt, transform=None, pre_transform=None):\n",
        "        self.cids = cids\n",
        "        self.data_path = data_path\n",
        "        self.gt = gt\n",
        "        super(MoleculeGraphDataset, self).__init__(root, transform, pre_transform)\n",
        "        \n",
        "        self.idx_to_cid = {}\n",
        "        i = 0\n",
        "        for raw_path in self.raw_paths:\n",
        "            cid = int(raw_path.split('/')[-1][:-6])\n",
        "            self.idx_to_cid[i] = cid\n",
        "            i += 1\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [cid + \".graph\" for cid in self.cids]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data_{}.pt'.format(cid) for cid in self.cids]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        shutil.copy(self.data_path, os.path.join(self.raw_dir, \"/mol_graphs.zip\"))\n",
        "        \n",
        "    def process_graph(self, raw_path):\n",
        "      edge_index  = []\n",
        "      x = []\n",
        "      with open(raw_path, 'r') as f:\n",
        "        next(f)\n",
        "        for line in f: #edges\n",
        "          if line != \"\\n\":\n",
        "            edge = *map(int, line.split()), \n",
        "            edge_index.append(edge)\n",
        "          else:\n",
        "            break\n",
        "        next(f)\n",
        "        for line in f: #get mol2vec features:\n",
        "          substruct_id = line.strip().split()[-1]\n",
        "          if substruct_id in self.gt.token_embs:\n",
        "            x.append(self.gt.token_embs[substruct_id])\n",
        "          else:\n",
        "            x.append(self.gt.token_embs['UNK'])\n",
        "\n",
        "        return torch.LongTensor(edge_index).T, torch.FloatTensor(x)\n",
        "\n",
        "\n",
        "\n",
        "    def process(self):\n",
        "      \n",
        "        with zipfile.ZipFile(os.path.join(self.raw_dir, \"/mol_graphs.zip\"), 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.raw_dir)\n",
        "\n",
        "\n",
        "        i = 0\n",
        "        for raw_path in self.raw_paths:\n",
        "            # Read data from `raw_path`.\n",
        "\n",
        "            cid = int(raw_path.split('/')[-1][:-6])\n",
        "\n",
        "            edge_index, x = self.process_graph(raw_path)\n",
        "            data = Data(x=x, edge_index = edge_index)\n",
        "\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "\n",
        "            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n",
        "            i += 1\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(self.idx_to_cid[idx])))\n",
        "        return data\n",
        "\n",
        "    def get_cid(self, cid):\n",
        "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n",
        "        return data\n",
        "\n",
        "#To get specific lists...\n",
        "\n",
        "class CustomGraphCollater(object):\n",
        "    def __init__(self, dataset, mask_len, follow_batch = [], exclude_keys = []):\n",
        "        self.follow_batch = follow_batch\n",
        "        self.exclude_keys = exclude_keys\n",
        "        self.dataset = dataset\n",
        "        self.mask_len = mask_len\n",
        "        self.mask_indices = np.array(range(mask_len))\n",
        "\n",
        "    def generate_mask(self, sz):\n",
        "        rv = torch.zeros((self.mask_len), dtype = torch.bool)\n",
        "        rv = rv.masked_fill(torch.BoolTensor(self.mask_indices < sz), bool(1)) #pytorch transformer input version\n",
        "        rv[-1] = 0 #set last value to 0 because pytorch can't handle all 1s\n",
        "        return rv\n",
        "\n",
        "    def get_masks(self, batch):\n",
        "      return torch.stack([self.generate_mask(b.x.shape[0]) for b in batch])\n",
        "\n",
        "    def collate(self, batch):\n",
        "        elem = batch[0]\n",
        "        if isinstance(elem, Data):\n",
        "            return Batch.from_data_list(batch) \n",
        "            \n",
        "        raise TypeError('DataLoader found invalid type: {}'.format(type(elem)))\n",
        "\n",
        "    def __call__(self, cids):\n",
        "      \n",
        "        tmp = [self.dataset.get_cid(int(cid)) for cid in cids]\n",
        "        return self.collate(tmp), self.get_masks(tmp)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbwoKag0Q1HG"
      },
      "source": [
        "root = 'graph-data/'\n",
        "graph_data_path = \"input/mol_graphs.zip\"\n",
        "\n",
        "\n",
        "mg_data_tr = MoleculeGraphDataset(root, gt.training_cids, graph_data_path, gt)\n",
        "graph_batcher_tr = CustomGraphCollater(mg_data_tr, gt.mol_trunc_length)\n",
        "\n",
        "mg_data_val = MoleculeGraphDataset(root, gt.validation_cids, graph_data_path, gt)\n",
        "graph_batcher_val = CustomGraphCollater(mg_data_val, gt.mol_trunc_length)\n",
        "\n",
        "mg_data_test = MoleculeGraphDataset(root, gt.test_cids, graph_data_path, gt)\n",
        "graph_batcher_test = CustomGraphCollater(mg_data_test, gt.mol_trunc_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFKkS8bGLSHL"
      },
      "source": [
        "#Get ranks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyepC0-oLRzh"
      },
      "source": [
        "\n",
        "dir1 = \"inputs/MLP1/embeddings/\"\n",
        "\n",
        "\n",
        "cids_train1 = np.load(dir1 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val1 = np.load(dir1 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test1 = np.load(dir1 + \"cids_test.npy\", allow_pickle=True)\n",
        "chem_embeddings_train1 = np.load(dir1 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val1 = np.load(dir1 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test1 = np.load(dir1 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train1 = np.load(dir1 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val1 = np.load(dir1 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test1 = np.load(dir1 + \"text_embeddings_test.npy\")\n",
        "\n",
        "\n",
        "all_chem_embbedings1 = np.concatenate((chem_embeddings_train1, chem_embeddings_val1, chem_embeddings_test1), axis = 0)\n",
        "\n",
        "cids_all = np.concatenate((cids_train1, cids_val1, cids_test1), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sRjU8VlLaEz"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def memory_efficient_similarity_matrix_custom(func, embedding1, embedding2, chunk_size = 1000):\n",
        "    rows = embedding1.shape[0]\n",
        "    \n",
        "    num_chunks = int(np.ceil(rows / chunk_size))\n",
        "    \n",
        "    for i in range(num_chunks):\n",
        "        end_chunk = (i+1)*(chunk_size) if (i+1)*(chunk_size) < rows else rows #account for smaller chunk at end...\n",
        "        yield func(embedding1[i*chunk_size:end_chunk,:], embedding2)\n",
        "\n",
        "#Calculate mean rank, hits at ten\n",
        "\n",
        "def dot_product(a, b):\n",
        "  return np.dot(a, b.T)\n",
        "  \n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "compose = lambda a,b: sigmoid(dot_product(a,b))\n",
        "\n",
        "text_chem_cos1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train1, all_chem_embbedings1)\n",
        "text_chem_cos_val1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val1, all_chem_embbedings1)\n",
        "text_chem_cos_test1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test1, all_chem_embbedings1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZqFQJO5QdqK"
      },
      "source": [
        "n_train = len(cids_train1)\n",
        "n_val = len(cids_val1)\n",
        "n_test = len(cids_test1)\n",
        "n = n_train + n_val + n_test\n",
        "\n",
        "offset_val = n_train\n",
        "offset_test = n_train + n_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xKRkUFKLajh"
      },
      "source": [
        "#For space 1:\n",
        "\n",
        "num_top = 10\n",
        "top_cids1 = {}\n",
        "top_cids_val1 = {}\n",
        "top_cids_test1 = {}\n",
        "scores_val1 = {}\n",
        "scores_test1 = {}\n",
        "\n",
        "ranks1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) #rank is actually double argsort...\n",
        "\n",
        "        top_cids1[cids_train1[j]] = [cids_all[loc] for loc in cid_locs[:num_top]]\n",
        "        \n",
        "        rank = ranks[j] + 1\n",
        "        ranks1.append(rank)\n",
        "        \n",
        "            \n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks1 = np.array(ranks1)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks1))\n",
        "print(\"Hits at 1:\", np.mean(ranks1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks1 <= 1000))\n",
        "\n",
        "print(\"Trainng MRR:\", np.mean(1/np.array(ranks1)))\n",
        "\n",
        "ranks_val1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) #rank is actually double argsort...\n",
        "\n",
        "        scores = np.sort(emb[k,:])[::-1]\n",
        "        \n",
        "        top_cids_val1[cids_val1[j]] = [cids_all[loc] for loc in cid_locs[:num_top]]\n",
        "        scores_val1[cids_val1[j]] = scores[:num_top]\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val1.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val1 = np.array(ranks_val1)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val1))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val1 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val1))\n",
        "\n",
        "\n",
        "ranks_test1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) #rank is actually double argsort...\n",
        "\n",
        "        scores = np.sort(emb[k,:])[::-1]\n",
        "        \n",
        "        top_cids_test1[cids_test1[j]] = [cids_all[loc] for loc in cid_locs[:num_top]]\n",
        "        scores_test1[cids_test1[j]] = scores[:num_top]\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test1.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "\n",
        "ranks_test1 = np.array(ranks_test1)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test1))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test1 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2LBn1iIMNnF"
      },
      "source": [
        "#Get Attention Association Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKMn2DNXabs0"
      },
      "source": [
        "import pickle \n",
        "\n",
        "path = \"input/\"\n",
        "with open(path + \"mha_weights.pkl\", 'rb') as fp:\n",
        "  mha_weights = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW8V39ECuM_w"
      },
      "source": [
        "all_mol_tokens = set()\n",
        "all_text_tokens = set()\n",
        "\n",
        "import zipfile\n",
        "archive = zipfile.ZipFile(graph_data_path, 'r')\n",
        "\n",
        "for i, cid in enumerate(mha_weights):\n",
        "  attn_weights = mha_weights[cid]\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "  \n",
        "  gfile = archive.open(cid + '.graph').read().decode('ascii')\n",
        "  mol_tokens = {}\n",
        "  idx = False\n",
        "  for line in gfile.split('\\n'):\n",
        "    line = line.strip()\n",
        "    if line == 'idx to identifier:': \n",
        "      idx = True\n",
        "      continue\n",
        "    if idx and len(line) != 0: \n",
        "      id, idf = line.split(\" \")\n",
        "      mol_tokens[id] = idf\n",
        "      \n",
        "  mol_tokens = list(mol_tokens.values())\n",
        "\n",
        "  all_mol_tokens.update(mol_tokens)\n",
        "  all_text_tokens.update(text_tokens)  \n",
        "\n",
        "mol_token_ids = {}\n",
        "text_token_ids = {} \n",
        "\n",
        "mol_token_ids_rev = {}\n",
        "text_token_ids_rev = {}\n",
        "for i, k in enumerate(all_mol_tokens):\n",
        "  mol_token_ids[k] = i\n",
        "  mol_token_ids_rev[i] = k\n",
        "for i, k in enumerate(all_text_tokens):\n",
        "  text_token_ids[k] = i\n",
        "  text_token_ids_rev[i] = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXZr2KWkv9vZ"
      },
      "source": [
        "\n",
        "support = np.zeros((len(all_text_tokens), len(all_mol_tokens)))\n",
        "conf = np.zeros((len(all_text_tokens), len(all_mol_tokens)))\n",
        "\n",
        "for i, cid in enumerate(mha_weights):\n",
        "  if cid in gt.validation_cids or cid in gt.test_cids: continue\n",
        "  attn_weights = mha_weights[cid]\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "    \n",
        "  gfile = archive.open(cid + '.graph').read().decode('ascii')\n",
        "  mol_tokens = {}\n",
        "  idx = False\n",
        "  for line in gfile.split('\\n'):\n",
        "    line = line.strip()\n",
        "    if line == 'idx to identifier:': \n",
        "      idx = True\n",
        "      continue\n",
        "    if idx and len(line) != 0: \n",
        "      id, idf = line.split(\" \")\n",
        "      mol_tokens[id] = idf\n",
        "  mol_tokens = list(mol_tokens.values())\n",
        "  \n",
        "  if len(mol_tokens) > gt.mol_trunc_length: mol_tokens = mol_tokens[:gt.mol_trunc_length]\n",
        "\n",
        "  for j, text in enumerate(text_tokens):\n",
        "    for k, molt in enumerate(mol_tokens):\n",
        "      support[text_token_ids[text], mol_token_ids[molt]] += attn_weights[j,k] #* mol_length # mol_length to normalize\n",
        "  \n",
        "  \n",
        "  if (i+1) % 1000 == 0: print(i+1)\n",
        "\n",
        "print(\"Support calculation finished.\")\n",
        "\n",
        "for j, text in enumerate(all_text_tokens):\n",
        "  if np.sum(support[text_token_ids[text], :]) == 0:\n",
        "    conf[text_token_ids[text], :] = 0.0\n",
        "  else:\n",
        "    conf[text_token_ids[text], :] = support[text_token_ids[text], :] / np.sum(support[text_token_ids[text], :])\n",
        "\n",
        "  if (j+1) % 1000 == 0: print(j+1)\n",
        "\n",
        "print(\"Confidence calculation finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdLGW10-tQ4U"
      },
      "source": [
        "#FPGrowth Pattern Mining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHYGBMyc8dg"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "all_mol_tokens = set()\n",
        "all_text_tokens = set()\n",
        "\n",
        "for i, cid in enumerate(gt.training_cids):\n",
        "  text_input = gt.text_tokenizer(gt.descriptions_train[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "  \n",
        "  mol_length = len(gt.molecule_sentences[cid].split())\n",
        "  mol_tokens = ['[CLS]']\n",
        "  mol_tokens.extend(gt.molecule_sentences[cid].split()[:mol_length])\n",
        "\n",
        "  all_mol_tokens.update(mol_tokens)\n",
        "  all_text_tokens.update(text_tokens)  \n",
        "\n",
        "mol_token_ids = defaultdict(lambda : -1)\n",
        "text_token_ids = defaultdict(lambda : -1) \n",
        "\n",
        "mol_token_ids_rev = {}\n",
        "text_token_ids_rev = {}\n",
        "for i, k in enumerate(all_mol_tokens):\n",
        "  mol_token_ids[k] = i\n",
        "  mol_token_ids_rev[i] = k\n",
        "for i, k in enumerate(all_text_tokens):\n",
        "  text_token_ids[k] = i\n",
        "  text_token_ids_rev[i] = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ibpssztSyD"
      },
      "source": [
        "#Create database\n",
        "\n",
        "database = []\n",
        "\n",
        "for cid in gt.training_cids:\n",
        "  if cid in gt.validation_cids: continue\n",
        "  text_input = gt.text_tokenizer(gt.descriptions_train[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "  text_tokens = text_tokens[1:-1] #skip [CLS], [SEP]\n",
        "\n",
        "  mol_length = len(gt.molecule_sentences[cid].split())\n",
        "  mol_tokens = gt.molecule_sentences[cid].split()[:mol_length]\n",
        "\n",
        "  all_tokens = []\n",
        "  all_tokens.extend(text_tokens)\n",
        "  all_tokens.extend(mol_tokens)\n",
        "\n",
        "  database.append(all_tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjeDpukHCSmu"
      },
      "source": [
        "print(\"Transactions:\", len(database))\n",
        "print(\"Item/Transaction\", np.mean([len(a) for a in database]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc792-_nB56A"
      },
      "source": [
        "!pip install mlxtend==0.17.0\n",
        "\n",
        "from mlxtend.frequent_patterns import fpgrowth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQidT8JtCHeu"
      },
      "source": [
        "import sys\n",
        "sys.setrecursionlimit(1500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55EAg3hvJxil"
      },
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "import pandas as pd\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(database).transform(database)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ecUMvYJ3UF"
      },
      "source": [
        "fp = fpgrowth(df, min_support=0.3, use_colnames=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wrMIdloX9Bq"
      },
      "source": [
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "rules = association_rules(fp, metric=\"confidence\", min_threshold=0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtYqBQSKYGDs"
      },
      "source": [
        "pd.set_option('display.max_columns', 4)\n",
        "\n",
        "print(rules[['antecedents', 'consequents', 'support', 'confidence']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xNz-wueMUEt"
      },
      "source": [
        "#Rerank - Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp_MJzGcZHyo"
      },
      "source": [
        "from itertools import combinations, chain\n",
        "\n",
        "\n",
        "def all_subsets(ss):#skip empty set\n",
        "    return chain(*map(lambda x: combinations(ss, x), range(1, len(ss)+1)))\n",
        "\n",
        "\n",
        "def generate_rules(text_tokens, mol_tokens):\n",
        "  candidates = set()\n",
        "  \n",
        "  text_subs = [frozenset([text_token_ids[j] for j in i]) for i in combinations(text_tokens, 1)]\n",
        "  mol_subs = [frozenset([mol_token_ids[j] for j in i]) for i in combinations(mol_tokens, 1)]\n",
        "\n",
        "  rules = []\n",
        "\n",
        "  for t in text_subs:\n",
        "    for m in mol_subs:\n",
        "      rules.append((t, m))\n",
        "\n",
        "  return rules\n",
        "\n",
        "\n",
        "def ar_score(text_cid, mol_cid, top_num=10):\n",
        "\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[text_cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "\n",
        "  gfile = archive.open(mol_cid + '.graph').read().decode('ascii')\n",
        "  mol_tokens = {}\n",
        "  idx = False\n",
        "  for line in gfile.split('\\n'):\n",
        "    line = line.strip()\n",
        "    if line == 'idx to identifier:': \n",
        "      idx = True\n",
        "      continue\n",
        "    if idx and len(line) != 0: \n",
        "      id, idf = line.split(\" \")\n",
        "      mol_tokens[id] = idf\n",
        "  mol_tokens = list(mol_tokens.values())\n",
        "\n",
        "  rules = generate_rules(text_tokens, mol_tokens)\n",
        "\n",
        "  tmp = np.array([conf[list(r[0])[0], list(r[1])[0]] for r in rules])\n",
        "\n",
        "  mx = np.min((top_num, len(tmp)))\n",
        "  top_confs = -np.partition(-tmp, mx-1)[:mx]\n",
        "\n",
        "\n",
        "  return np.mean(top_confs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSnEe4UMUwX"
      },
      "source": [
        "\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "\n",
        "alpha = 0.0\n",
        "\n",
        "\n",
        "ar_scores = np.zeros((len(top_cids_val1), num_top))\n",
        "\n",
        "new_ranks_val = []\n",
        "for i, cid in enumerate(top_cids_val1):\n",
        "  \n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "\n",
        "  score = np.zeros((num_top))\n",
        "  for j, cid2 in enumerate(top_cids_val1[cid]):\n",
        "    gfile = archive.open(cid + '.graph').read().decode('ascii')\n",
        "    mol_tokens = {}\n",
        "    idx = False\n",
        "    for line in gfile.split('\\n'):\n",
        "      line = line.strip()\n",
        "      if line == 'idx to identifier:':\n",
        "        idx = True\n",
        "        continue\n",
        "      if idx and len(line) != 0: \n",
        "        id, idf = line.split(\" \")\n",
        "        mol_tokens[id] = idf\n",
        "    mol_tokens = list(mol_tokens.values())\n",
        "\n",
        "    tmp = ar_score(cid, cid2)\n",
        "    ar_scores[i,j] = tmp\n",
        "    score[j] = alpha * scores_val1[cid][j] + (1 - alpha) * tmp\n",
        "    \n",
        "  try:\n",
        "    old_loc = top_cids_val1[cid].index(cid)\n",
        "    \n",
        "    sorted = np.argsort(-score, kind='stable')\n",
        "    \n",
        "    new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "    \n",
        "  except ValueError:\n",
        "    new_rank = ranks_val1[i]\n",
        "\n",
        "  new_ranks_val.append(new_rank)\n",
        "  \n",
        "      \n",
        "  if (i+1) % 200 == 0: print(i+1)\n",
        "\n",
        "new_ranks_val = np.array(new_ranks_val)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(new_ranks_val))\n",
        "print(\"Hits at 1:\", np.mean(new_ranks_val <= 1))\n",
        "print(\"Hits at 10:\", np.mean(new_ranks_val <= 10))\n",
        "print(\"Hits at 100:\", np.mean(new_ranks_val <= 100))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/np.array(new_ranks_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYe8W7AXb3vv"
      },
      "source": [
        "\n",
        "x = np.linspace(0.0,1,101)\n",
        "MRRs = []\n",
        "hits1 = []\n",
        "hits10 = []\n",
        "\n",
        "\n",
        "for n in x:\n",
        "  alpha = n\n",
        "\n",
        "  hits_at_one = 0\n",
        "  hits_at_ten = 0\n",
        "  hits_at_100 = 0\n",
        "\n",
        "  tmp_ranks = []\n",
        "  for i, cid in enumerate(top_cids_val1):\n",
        "    \n",
        "    score = np.zeros((num_top))\n",
        "    for j, cid2 in enumerate(top_cids_val1[cid]):\n",
        "      score[j] = alpha * scores_val1[cid][j] + (1 - alpha) * ar_scores[i,j]\n",
        "\n",
        "    try:\n",
        "      old_loc = top_cids_val1[cid].index(cid)\n",
        "      \n",
        "      sorted = np.argsort(-score, kind='stable')\n",
        "      \n",
        "      new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "      \n",
        "    except ValueError:\n",
        "      new_rank = ranks_val1[i]\n",
        "\n",
        "    tmp_ranks.append(new_rank)\n",
        "    \n",
        "    if new_rank <= 1:\n",
        "        hits_at_one += 1\n",
        "    if new_rank <= 10:\n",
        "        hits_at_ten += 1\n",
        "    if new_rank <= 100:\n",
        "        hits_at_100 += 1\n",
        "  \n",
        "  MRRs.append(np.mean(1/np.array(tmp_ranks)))\n",
        "  hits1.append(hits_at_one/cids_val1.size)\n",
        "  hits10.append(hits_at_ten/cids_val1.size)\n",
        "  \n",
        "  \n",
        "print(\"Val Mean rank:\", np.mean(tmp_ranks))\n",
        "print(\"Hits at 1:\", hits_at_one/cids_val1.size)\n",
        "print(\"Hits at 10:\", hits_at_ten/cids_val1.size)\n",
        "print(\"Hits at 100:\", hits_at_100/cids_val1.size)\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/np.array(tmp_ranks)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkXG0K_z33g"
      },
      "source": [
        "\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "\n",
        "alpha = x[np.argmax(MRRs)]\n",
        "\n",
        "ar_scores_test = np.zeros((len(top_cids_test1), num_top))\n",
        "\n",
        "new_ranks_test = []\n",
        "for i, cid in enumerate(top_cids_test1):\n",
        "  \n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "\n",
        "  score = np.zeros((num_top))\n",
        "  for j, cid2 in enumerate(top_cids_test1[cid]):\n",
        "    gfile = archive.open(cid + '.graph').read().decode('ascii')\n",
        "    mol_tokens = {}\n",
        "    idx = False\n",
        "    for line in gfile.split('\\n'):\n",
        "      line = line.strip()\n",
        "      if line == 'idx to identifier:': \n",
        "        idx = True\n",
        "        continue\n",
        "      if idx and len(line) != 0: \n",
        "        id, idf = line.split(\" \")\n",
        "        mol_tokens[id] = idf\n",
        "    mol_tokens = list(mol_tokens.values())\n",
        "\n",
        "    tmp = ar_score(cid, cid2)\n",
        "    ar_scores_test[i,j] = tmp\n",
        "    score[j] = alpha * scores_test1[cid][j] + (1 - alpha) * tmp\n",
        "    \n",
        "  try:\n",
        "    old_loc = top_cids_test1[cid].index(cid)\n",
        "    \n",
        "    sorted = np.argsort(-score, kind='stable')\n",
        "    \n",
        "    new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "    \n",
        "  except ValueError:\n",
        "    new_rank = ranks_test1[i]\n",
        "\n",
        "  new_ranks_test.append(new_rank)\n",
        "  \n",
        "      \n",
        "  if (i+1) % 200 == 0: print(i+1)\n",
        "\n",
        "new_ranks_test = np.array(new_ranks_test)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(new_ranks_test))\n",
        "print(\"Hits at 1:\", np.mean(new_ranks_test <= 1))\n",
        "print(\"Hits at 10:\", np.mean(new_ranks_test <= 10))\n",
        "print(\"Hits at 100:\", np.mean(new_ranks_test <= 100))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/np.array(new_ranks_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYsD7Kb0aO-y"
      },
      "source": [
        "#1->1 normal pattern mining and rerank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWoIzJiBaWqU"
      },
      "source": [
        "#based off FP-growth for 1->1\n",
        "normal_support = np.zeros((len(all_text_tokens), len(all_mol_tokens)))\n",
        "normal_conf = np.zeros((len(all_text_tokens), len(all_mol_tokens)))\n",
        "\n",
        "#Create database\n",
        "\n",
        "for i, cid in enumerate(gt.training_cids):\n",
        "\n",
        "  if cid in gt.validation_cids or cid in gt.test_cids: continue\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "  \n",
        "  gfile = archive.open(cid + '.graph').read().decode('ascii')\n",
        "  mol_tokens = {}\n",
        "  idx = False\n",
        "  for line in gfile.split('\\n'):\n",
        "    line = line.strip()\n",
        "    if line == 'idx to identifier:': \n",
        "      idx = True\n",
        "      continue\n",
        "    if idx and len(line) != 0: \n",
        "      id, idf = line.split(\" \")\n",
        "      mol_tokens[id] = idf\n",
        "      \n",
        "  mol_tokens = list(mol_tokens.values())\n",
        "  \n",
        "  if len(mol_tokens) > gt.mol_trunc_length: mol_tokens = mol_tokens[:gt.mol_trunc_length]\n",
        "\n",
        "  for j, text in enumerate(text_tokens):\n",
        "    for k, molt in enumerate(mol_tokens):\n",
        "      normal_support[text_token_ids[text], mol_token_ids[molt]] += 1\n",
        "\n",
        "\n",
        "  if (i+1) % 1000 == 0: print(i+1)\n",
        "\n",
        "print(\"Support calculation finished.\")\n",
        "\n",
        "for j, text in enumerate(all_text_tokens):\n",
        "  normal_conf[text_token_ids[text], :] = normal_support[text_token_ids[text], :] / np.sum(normal_support[text_token_ids[text], :])\n",
        "\n",
        "  if (j+1) % 1000 == 0: print(j+1)\n",
        "\n",
        "print(\"Confidence calculation finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wggemnlUd3Tx"
      },
      "source": [
        "from itertools import combinations, chain\n",
        "\n",
        "\n",
        "def all_subsets(ss):#skip empty set\n",
        "    return chain(*map(lambda x: combinations(ss, x), range(1, len(ss)+1)))\n",
        "\n",
        "\n",
        "def generate_rules(text_tokens, mol_tokens):\n",
        "  candidates = set()\n",
        "  \n",
        "  text_subs = [frozenset([text_token_ids[j] for j in i]) for i in combinations(text_tokens, 1)]\n",
        "  mol_subs = [frozenset([mol_token_ids[j] for j in i]) for i in combinations(mol_tokens, 1)]\n",
        "\n",
        "  rules = []\n",
        "\n",
        "  for t in text_subs:\n",
        "    for m in mol_subs:\n",
        "      rules.append((t, m))\n",
        "\n",
        "  return rules\n",
        "\n",
        "\n",
        "def ar_score(text_cid, mol_cid, top_num=10):\n",
        "\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[text_cid], truncation=True, padding = 'max_length', \n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  text_tokens = gt.text_tokenizer.convert_ids_to_tokens(text_input['input_ids'][:text_length])\n",
        "\n",
        "  gfile = archive.open(mol_cid + '.graph').read().decode('ascii')\n",
        "  mol_tokens = {}\n",
        "  idx = False\n",
        "  for line in gfile.split('\\n'):\n",
        "    line = line.strip()\n",
        "    if line == 'idx to identifier:': \n",
        "      idx = True\n",
        "      continue\n",
        "    if idx and len(line) != 0: \n",
        "      id, idf = line.split(\" \")\n",
        "      mol_tokens[id] = idf\n",
        "  mol_tokens = list(mol_tokens.values())\n",
        "\n",
        "  rules = generate_rules(text_tokens, mol_tokens)\n",
        "\n",
        "  tmp = np.array([normal_conf[list(r[0])[0], list(r[1])[0]] for r in rules])\n",
        "\n",
        "\n",
        "  mx = np.min((top_num, len(tmp)))\n",
        "  top_confs = -np.partition(-tmp, mx-1)[:mx]\n",
        "\n",
        "  return np.mean(top_confs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r3jWCYId9GB"
      },
      "source": [
        "\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "\n",
        "alpha = 0.0\n",
        "\n",
        "\n",
        "hits_at_one = 0\n",
        "hits_at_ten = 0\n",
        "hits_at_100 = 0\n",
        "\n",
        "ar_scores = np.zeros((len(top_cids_val1), num_top))\n",
        "\n",
        "new_ranks_val = []\n",
        "for i, cid in enumerate(top_cids_val1):\n",
        "\n",
        "  score = np.zeros((num_top))\n",
        "  for j, cid2 in enumerate(top_cids_val1[cid]):\n",
        "    tmp = ar_score(cid, cid2)\n",
        "    ar_scores[i,j] = tmp\n",
        "    score[j] = alpha * scores_val1[cid][j] + (1 - alpha) * tmp\n",
        "  try:\n",
        "    old_loc = top_cids_val1[cid].index(cid)\n",
        "    \n",
        "    sorted = np.argsort(-score, kind='stable')\n",
        "    \n",
        "    new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "    \n",
        "  except ValueError:\n",
        "    new_rank = ranks_val1[i]\n",
        "\n",
        "  new_ranks_val.append(new_rank)\n",
        "  \n",
        "  if new_rank <= 1:\n",
        "      hits_at_one += 1\n",
        "  if new_rank <= 10:\n",
        "      hits_at_ten += 1\n",
        "  if new_rank <= 100:\n",
        "      hits_at_100 += 1\n",
        "      \n",
        "  if (i+1) % 200 == 0: print(i+1)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(new_ranks_val))\n",
        "print(\"Hits at 1:\", hits_at_one/cids_val1.size)\n",
        "print(\"Hits at 10:\", hits_at_ten/cids_val1.size)\n",
        "print(\"Hits at 100:\", hits_at_100/cids_val1.size)\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/np.array(new_ranks_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62bQRftceCaq"
      },
      "source": [
        "\n",
        "x = np.linspace(0.0,1,101)\n",
        "MRRs = []\n",
        "hits1 = []\n",
        "hits10 = []\n",
        "\n",
        "\n",
        "for n in x:\n",
        "  alpha = n\n",
        "\n",
        "  hits_at_one = 0\n",
        "  hits_at_ten = 0\n",
        "  hits_at_100 = 0\n",
        "\n",
        "  tmp_ranks = []\n",
        "  for i, cid in enumerate(top_cids_val1):\n",
        "    \n",
        "    score = np.zeros((num_top))\n",
        "    for j, cid2 in enumerate(top_cids_val1[cid]):\n",
        "      score[j] = alpha * scores_val1[cid][j] + (1 - alpha) * ar_scores[i,j]\n",
        "\n",
        "    try:\n",
        "      old_loc = top_cids_val1[cid].index(cid)\n",
        "      \n",
        "      sorted = np.argsort(-score, kind='stable')\n",
        "      \n",
        "      new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "      \n",
        "    except ValueError:\n",
        "      new_rank = ranks_val1[i]\n",
        "\n",
        "    tmp_ranks.append(new_rank)\n",
        "    \n",
        "    if new_rank <= 1:\n",
        "        hits_at_one += 1\n",
        "    if new_rank <= 10:\n",
        "        hits_at_ten += 1\n",
        "    if new_rank <= 100:\n",
        "        hits_at_100 += 1\n",
        "  \n",
        "  MRRs.append(np.mean(1/np.array(tmp_ranks)))\n",
        "  hits1.append(hits_at_one/cids_val1.size)\n",
        "  hits10.append(hits_at_ten/cids_val1.size)\n",
        "  \n",
        "print(\"Val Mean rank:\", np.mean(tmp_ranks))\n",
        "print(\"Hits at 1:\", hits_at_one/cids_val1.size)\n",
        "print(\"Hits at 10:\", hits_at_ten/cids_val1.size)\n",
        "print(\"Hits at 100:\", hits_at_100/cids_val1.size)\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/np.array(tmp_ranks)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlWAnbSmtIrI"
      },
      "source": [
        "\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "\n",
        "alpha = 0.0\n",
        "\n",
        "\n",
        "hits_at_one = 0\n",
        "hits_at_ten = 0\n",
        "hits_at_100 = 0\n",
        "\n",
        "ar_scores_test = np.zeros((len(top_cids_test1), num_top))\n",
        "\n",
        "new_ranks_test = []\n",
        "for i, cid in enumerate(top_cids_test1):\n",
        "\n",
        "  score = np.zeros((num_top))\n",
        "  for j, cid2 in enumerate(top_cids_test1[cid]):\n",
        "    \n",
        "    tmp = ar_score(cid, cid2)\n",
        "    ar_scores_test[i,j] = tmp\n",
        "    score[j] = alpha * scores_test1[cid][j] + (1 - alpha) * tmp\n",
        "  try:\n",
        "    old_loc = top_cids_test1[cid].index(cid)\n",
        "    \n",
        "    sorted = np.argsort(-score, kind='stable')\n",
        "    \n",
        "    new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "    \n",
        "  except ValueError:\n",
        "    new_rank = ranks_test1[i]\n",
        "\n",
        "  new_ranks_test.append(new_rank)\n",
        "  \n",
        "  if new_rank <= 1:\n",
        "      hits_at_one += 1\n",
        "  if new_rank <= 10:\n",
        "      hits_at_ten += 1\n",
        "  if new_rank <= 100:\n",
        "      hits_at_100 += 1\n",
        "      \n",
        "  if (i+1) % 200 == 0: print(i+1)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(new_ranks_test))\n",
        "print(\"Hits at 1:\", hits_at_one/cids_test1.size)\n",
        "print(\"Hits at 10:\", hits_at_ten/cids_test1.size)\n",
        "print(\"Hits at 100:\", hits_at_100/cids_test1.size)\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/np.array(new_ranks_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VZZFcw3xBKf"
      },
      "source": [
        "\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "\n",
        "first = np.argmax(MRRs)\n",
        "last = len(MRRs) - np.argmax(MRRs[::-1])\n",
        "\n",
        "alpha = (x[first] + x[last])/2\n",
        "print(alpha)\n",
        "\n",
        "hits_at_one = 0\n",
        "hits_at_ten = 0\n",
        "hits_at_100 = 0\n",
        "\n",
        "new_ranks_test = []\n",
        "for i, cid in enumerate(top_cids_test1):\n",
        "  \n",
        "\n",
        "  score = np.zeros((num_top))\n",
        "  for j, cid2 in enumerate(top_cids_test1[cid]):\n",
        "    \n",
        "    score[j] = alpha * scores_test1[cid][j] + (1 - alpha) * ar_scores_test[i,j]\n",
        "  try:\n",
        "    old_loc = top_cids_test1[cid].index(cid)\n",
        "    \n",
        "    sorted = np.argsort(-score, kind='stable')\n",
        "    \n",
        "    new_rank = np.where(sorted == old_loc)[0][0] + 1\n",
        "    \n",
        "  except ValueError:\n",
        "    new_rank = ranks_test1[i]\n",
        "\n",
        "  new_ranks_test.append(new_rank)\n",
        "  \n",
        "  if new_rank <= 1:\n",
        "      hits_at_one += 1\n",
        "  if new_rank <= 10:\n",
        "      hits_at_ten += 1\n",
        "  if new_rank <= 100:\n",
        "      hits_at_100 += 1\n",
        "      \n",
        "  if (i+1) % 200 == 0: print(i+1)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(new_ranks_test))\n",
        "print(\"Hits at 1:\", hits_at_one/cids_test1.size)\n",
        "print(\"Hits at 10:\", hits_at_ten/cids_test1.size)\n",
        "print(\"Hits at 100:\", hits_at_100/cids_test1.size)\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/np.array(new_ranks_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}