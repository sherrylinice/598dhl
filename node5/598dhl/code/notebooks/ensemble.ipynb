{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8MSZ5412kEU"
      },
      "outputs": [],
      "source": [
        "dir1 = \"inputs/GCN1/embeddings/\"\n",
        "dir2 = \"inputs/GCN2/embeddings/\"\n",
        "dir3 = \"inputs/GCN3/embeddings/\"\n",
        "dir4 = \"inputs/MLP1/embeddings/\"\n",
        "dir5 = \"inputs/MLP2/embeddings/\"\n",
        "dir6 = \"inputs/MLP3/embeddings/\"\n",
        "\n",
        "\n",
        "cids_train1 = np.load(dir1 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val1 = np.load(dir1 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test1 = np.load(dir1 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train1 = np.load(dir1 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val1 = np.load(dir1 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test1 = np.load(dir1 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train1 = np.load(dir1 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val1 = np.load(dir1 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test1 = np.load(dir1 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train2 = np.load(dir2 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val2 = np.load(dir2 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test2 = np.load(dir2 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train2 = np.load(dir2 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val2 = np.load(dir2 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test2 = np.load(dir2 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train2 = np.load(dir2 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val2 = np.load(dir2 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test2 = np.load(dir2 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train3 = np.load(dir3 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val3 = np.load(dir3 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test3 = np.load(dir3 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train3 = np.load(dir3 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val3 = np.load(dir3 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test3 = np.load(dir3 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train3 = np.load(dir3 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val3 = np.load(dir3 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test3 = np.load(dir3 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train4 = np.load(dir4 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val4 = np.load(dir4 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test4 = np.load(dir4 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train4 = np.load(dir4 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val4 = np.load(dir4 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test4 = np.load(dir4 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train4 = np.load(dir4 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val4 = np.load(dir4 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test4 = np.load(dir4 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train5 = np.load(dir5 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val5 = np.load(dir5 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test5 = np.load(dir5 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train5 = np.load(dir5 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val5 = np.load(dir5 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test5 = np.load(dir5 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train5 = np.load(dir5 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val5 = np.load(dir5 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test5 = np.load(dir5 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train6 = np.load(dir6 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val6 = np.load(dir6 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test6 = np.load(dir6 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train6 = np.load(dir6 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val6 = np.load(dir6 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test6 = np.load(dir6 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train6 = np.load(dir6 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val6 = np.load(dir6 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test6 = np.load(dir6 + \"text_embeddings_test.npy\")\n",
        "\n",
        "#Reorder (this is very important):\n",
        "tmp = cids_train2.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val2.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test2.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train2 = cids_train2[indexes]\n",
        "cids_val2 = cids_val2[indexes_val]\n",
        "cids_test2 = cids_test2[indexes_test]\n",
        "\n",
        "chem_embeddings_train2 = chem_embeddings_train2[indexes]\n",
        "text_embeddings_train2 = text_embeddings_train2[indexes]\n",
        "chem_embeddings_val2 = chem_embeddings_val2[indexes_val]\n",
        "text_embeddings_val2 = text_embeddings_val2[indexes_val]\n",
        "chem_embeddings_test2 = chem_embeddings_test2[indexes_test]\n",
        "text_embeddings_test2 = text_embeddings_test2[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train3.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val3.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test3.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train3 = cids_train3[indexes]\n",
        "cids_val3 = cids_val3[indexes_val]\n",
        "cids_test3 = cids_test3[indexes_test]\n",
        "\n",
        "chem_embeddings_train3 = chem_embeddings_train3[indexes]\n",
        "text_embeddings_train3 = text_embeddings_train3[indexes]\n",
        "chem_embeddings_val3 = chem_embeddings_val3[indexes_val]\n",
        "text_embeddings_val3 = text_embeddings_val3[indexes_val]\n",
        "chem_embeddings_test3 = chem_embeddings_test3[indexes_test]\n",
        "text_embeddings_test3 = text_embeddings_test3[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train4.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val4.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test4.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train4 = cids_train4[indexes]\n",
        "cids_val4 = cids_val4[indexes_val]\n",
        "cids_test4 = cids_test4[indexes_test]\n",
        "\n",
        "chem_embeddings_train4 = chem_embeddings_train4[indexes]\n",
        "text_embeddings_train4 = text_embeddings_train4[indexes]\n",
        "chem_embeddings_val4 = chem_embeddings_val4[indexes_val]\n",
        "text_embeddings_val4 = text_embeddings_val4[indexes_val]\n",
        "chem_embeddings_test4 = chem_embeddings_test4[indexes_test]\n",
        "text_embeddings_test4 = text_embeddings_test4[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train5.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val5.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test5.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train5 = cids_train5[indexes]\n",
        "cids_val5 = cids_val5[indexes_val]\n",
        "cids_test5 = cids_test5[indexes_test]\n",
        "\n",
        "chem_embeddings_train5 = chem_embeddings_train5[indexes]\n",
        "text_embeddings_train5 = text_embeddings_train5[indexes]\n",
        "chem_embeddings_val5 = chem_embeddings_val5[indexes_val]\n",
        "text_embeddings_val5 = text_embeddings_val5[indexes_val]\n",
        "chem_embeddings_test5 = chem_embeddings_test5[indexes_test]\n",
        "text_embeddings_test5 = text_embeddings_test5[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train6.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val6.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test6.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train6 = cids_train6[indexes]\n",
        "cids_val6 = cids_val6[indexes_val]\n",
        "cids_test6 = cids_test6[indexes_test]\n",
        "\n",
        "chem_embeddings_train6 = chem_embeddings_train6[indexes]\n",
        "text_embeddings_train6 = text_embeddings_train6[indexes]\n",
        "chem_embeddings_val6 = chem_embeddings_val6[indexes_val]\n",
        "text_embeddings_val6 = text_embeddings_val6[indexes_val]\n",
        "chem_embeddings_test6 = chem_embeddings_test6[indexes_test]\n",
        "text_embeddings_test6 = text_embeddings_test6[indexes_test]\n",
        "\n",
        "\n",
        "all_chem_embbedings1 = np.concatenate((chem_embeddings_train1, chem_embeddings_val1, chem_embeddings_test1), axis = 0)\n",
        "all_chem_embbedings2 = np.concatenate((chem_embeddings_train2, chem_embeddings_val2, chem_embeddings_test2), axis = 0)\n",
        "all_chem_embbedings3 = np.concatenate((chem_embeddings_train3, chem_embeddings_val3, chem_embeddings_test3), axis = 0)\n",
        "all_chem_embbedings4 = np.concatenate((chem_embeddings_train4, chem_embeddings_val4, chem_embeddings_test4), axis = 0)\n",
        "all_chem_embbedings5 = np.concatenate((chem_embeddings_train5, chem_embeddings_val5, chem_embeddings_test5), axis = 0)\n",
        "all_chem_embbedings6 = np.concatenate((chem_embeddings_train6, chem_embeddings_val6, chem_embeddings_test6), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1c3q5tMX8S5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def memory_efficient_similarity_matrix_custom(func, embedding1, embedding2, chunk_size = 1000):\n",
        "    rows = embedding1.shape[0]\n",
        "    \n",
        "    num_chunks = int(np.ceil(rows / chunk_size))\n",
        "    \n",
        "    for i in range(num_chunks):\n",
        "        end_chunk = (i+1)*(chunk_size) if (i+1)*(chunk_size) < rows else rows #account for smaller chunk at end...\n",
        "        yield func(embedding1[i*chunk_size:end_chunk,:], embedding2)\n",
        "\n",
        "\n",
        "text_chem_cos1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train1, all_chem_embbedings1)\n",
        "text_chem_cos_val1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val1, all_chem_embbedings1)\n",
        "text_chem_cos_test1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test1, all_chem_embbedings1)\n",
        "\n",
        "text_chem_cos2 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train2, all_chem_embbedings2)\n",
        "text_chem_cos_val2 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val2, all_chem_embbedings2)\n",
        "text_chem_cos_test2 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test2, all_chem_embbedings2)\n",
        "\n",
        "text_chem_cos3 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train3, all_chem_embbedings3)\n",
        "text_chem_cos_val3 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val3, all_chem_embbedings3)\n",
        "text_chem_cos_test3 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test3, all_chem_embbedings3)\n",
        "\n",
        "text_chem_cos4 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train4, all_chem_embbedings4)\n",
        "text_chem_cos_val4 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val4, all_chem_embbedings4)\n",
        "text_chem_cos_test4 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test4, all_chem_embbedings4)\n",
        "\n",
        "text_chem_cos5 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train5, all_chem_embbedings5)\n",
        "text_chem_cos_val5 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val5, all_chem_embbedings5)\n",
        "text_chem_cos_test5 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test5, all_chem_embbedings5)\n",
        "\n",
        "text_chem_cos6 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train6, all_chem_embbedings6)\n",
        "text_chem_cos_val6 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val6, all_chem_embbedings6)\n",
        "text_chem_cos_test6 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test6, all_chem_embbedings6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHaXqxabUMIM"
      },
      "outputs": [],
      "source": [
        "n_train = len(cids_train1)\n",
        "n_val = len(cids_val2)\n",
        "n_test = len(cids_test1)\n",
        "n = n_train + n_val + n_test\n",
        "\n",
        "offset_val = n_train\n",
        "offset_test = n_train + n_val\n",
        "\n",
        "cids_all = np.concatenate((cids_train1, cids_val1, cids_test1), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeiE_f5sfXi_"
      },
      "outputs": [],
      "source": [
        "tr_ranks_avg = np.zeros((n_train, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YLeGjn3lw0U"
      },
      "outputs": [],
      "source": [
        "val_avg_ranks = np.zeros((n_val, n))\n",
        "test_avg_ranks = np.zeros((n_test, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSJO3N3rX-RO"
      },
      "outputs": [],
      "source": [
        "#For space 1:\n",
        "\n",
        "\n",
        "tr_correct1 = np.zeros(len(cids_train1))\n",
        "\n",
        "hits_at_one = 0\n",
        "hits_at_ten = 0\n",
        "hits_at_100 = 0\n",
        "hits_at_500 = 0\n",
        "hits_at_1000 = 0\n",
        "ranks1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) #rank is actually double argsort.\n",
        "        \n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks \n",
        "        \n",
        "\n",
        "        tr_correct1[j] = ranks[j] + 1\n",
        "        rank = ranks[j] + 1\n",
        "        ranks1.append(rank)\n",
        "        \n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks1 = np.array(ranks1)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks1))\n",
        "print(\"Hits at 1:\", np.mean(ranks1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks1 <= 1000))\n",
        "\n",
        "print(\"Trainng MRR:\", np.mean(1/np.array(ranks1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHCE8t4xkEEo"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_val1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks \n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val1.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val1 = np.array(ranks_val1)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val1))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val1 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHtt2av9sTSY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "ranks_test1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test1.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "ranks_test1 = np.array(ranks_test1)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test1))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test1 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTGLQhjCcNcQ"
      },
      "outputs": [],
      "source": [
        "#For space 2:\n",
        "\n",
        "ranks2 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos2):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks \n",
        "\n",
        "        rank = ranks[j] + 1\n",
        "        ranks2.append(rank)\n",
        "        \n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks2 = np.array(ranks2)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks2))\n",
        "print(\"Hits at 1:\", np.mean(ranks2 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks2 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks2 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks2 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks2 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJVdQ3gnkF6h"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_val2 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val2):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val2.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val2 = np.array(ranks_val2)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val2))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val2 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val2 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val2 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val2 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val2 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b--eYvc1tmdB"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_test2 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test2):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "        \n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test2.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "ranks_test2 = np.array(ranks_test2)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test2))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test2 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test2 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test2 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test2 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test2 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-O544rBjuPV"
      },
      "outputs": [],
      "source": [
        "#For space 3:\n",
        "\n",
        "ranks3 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos3):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "        \n",
        "        rank = ranks[j] + 1\n",
        "        ranks3.append(rank)\n",
        "        \n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks3 = np.array(ranks3)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks3))\n",
        "print(\"Hits at 1:\", np.mean(ranks3 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks3 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks3 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks3 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks3 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUHkwFDij3Wo"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_val3 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val3):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val3.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val3 = np.array(ranks_val3)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val3))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val3 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val3 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val3 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val3 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val3 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ejG82D7aG9v"
      },
      "outputs": [],
      "source": [
        "tmp = cids_all[np.argsort(val_avg_ranks[1396,:])]\n",
        "print(tmp)\n",
        "print(np.where(tmp == '45359507')[0][0] + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBQAScCBj9_o"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_test3 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test3):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "        \n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test3.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "ranks_test3 = np.array(ranks_test3)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test3))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test3 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test3 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test3 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test3 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test3 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fVP9qVuZJSd"
      },
      "outputs": [],
      "source": [
        "#For space 4:\n",
        "\n",
        "ranks4 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos4):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j] + 1\n",
        "        ranks4.append(rank)\n",
        "        \n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks4 = np.array(ranks4)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks4))\n",
        "print(\"Hits at 1:\", np.mean(ranks4 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks4 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks4 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks4 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks4 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdtt4pqoZSG-"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_val4 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val4):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks \n",
        "        \n",
        "        \n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val4.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val4 = np.array(ranks_val4)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val4))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val4 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val4 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val4 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val4 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val4 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgb8DZyGZaeB"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_test4 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test4):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "        \n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test4.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "ranks_test4 = np.array(ranks_test4)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test4))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test4 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test4 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test4 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test4 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test4 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYBg8DgLLF77"
      },
      "outputs": [],
      "source": [
        "#For space 5:\n",
        "\n",
        "ranks5 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos5):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j] + 1\n",
        "        ranks5.append(rank)\n",
        "        \n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks5 = np.array(ranks5)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks5))\n",
        "print(\"Hits at 1:\", np.mean(ranks5 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks5 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks5 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks5 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks5 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciC1UHCULOHu"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_val5 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val5):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val5.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val5 = np.array(ranks_val5)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val5))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val5 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val5 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val5 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val5 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val5 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnNAtefpLUIo"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_test5 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test5):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "        \n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test5.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "ranks_test5 = np.array(ranks_test5)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test5))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test5 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test5 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test5 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test5 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test5 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THVsmON8LZhD"
      },
      "outputs": [],
      "source": [
        "#For space 6:\n",
        "\n",
        "ranks6 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos6):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j] + 1\n",
        "        ranks6.append(rank)\n",
        "        \n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks6 = np.array(ranks6)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks6))\n",
        "print(\"Hits at 1:\", np.mean(ranks6 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks6 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks6 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks6 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks6 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMx_msazLf0M"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_val6 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val6):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) \n",
        "        \n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks \n",
        "        \n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val6.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "    \n",
        "\n",
        "ranks_val6 = np.array(ranks_val6)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val6))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val6 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val6 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val6 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val6 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val6 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h5XSGf3LmHV"
      },
      "outputs": [],
      "source": [
        "\n",
        "ranks_test6 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test6):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "        \n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "        \n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test6.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "    \n",
        "ranks_test6 = np.array(ranks_test6)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test6))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test6 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test6 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test6 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test6 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test6 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P3nT85ythbh"
      },
      "source": [
        "#Rerank from sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4tFZs1B1afY"
      },
      "outputs": [],
      "source": [
        "\n",
        "sorted = np.argsort(tr_ranks_avg)\n",
        "new_tr_ranks = np.diag(np.argsort(sorted)) + 1\n",
        "\n",
        "print(np.mean(new_tr_ranks))\n",
        "print(\"%1:\", np.mean(new_tr_ranks <= 1))\n",
        "print(\"%10:\", np.mean(new_tr_ranks <= 10))\n",
        "print(\"%100:\", np.mean(new_tr_ranks <= 100))\n",
        "\n",
        "print(\"Trainng MRR:\", np.mean(1/np.array(new_tr_ranks)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EysOkgIrz2pf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "sorted = np.argsort(val_avg_ranks)\n",
        "val_final_ranks = np.argsort(sorted) + 1\n",
        "new_val_ranks = np.diag(val_final_ranks[:,offset_val:offset_test])\n",
        "\n",
        "print(np.mean(new_val_ranks))\n",
        "print(\"%1:\", np.mean(new_val_ranks <= 1))\n",
        "print(\"%10:\", np.mean(new_val_ranks <= 10))\n",
        "print(\"%100:\", np.mean(new_val_ranks <= 100))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/np.array(new_val_ranks)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKwl8NzwuUF1"
      },
      "outputs": [],
      "source": [
        "\n",
        "sorted = np.argsort(test_avg_ranks)\n",
        "test_final_ranks = np.argsort(sorted) + 1\n",
        "new_test_ranks = np.diag(test_final_ranks[:,offset_test:])\n",
        "\n",
        "print(np.mean(new_test_ranks))\n",
        "print(\"%1:\", np.mean(new_test_ranks <= 1))\n",
        "print(\"%10:\", np.mean(new_test_ranks <= 10))\n",
        "print(\"%100:\", np.mean(new_test_ranks <= 100))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/new_test_ranks))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Ensemble_submit.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
